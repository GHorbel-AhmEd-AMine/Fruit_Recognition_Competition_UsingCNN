{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vgg16_99.99.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck1HorwY_uD2"
      },
      "source": [
        "#Loading Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EP8Xwl7_248"
      },
      "source": [
        "**All Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.**\n",
        "\n",
        "**We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, tensorlow --> tf).**\n",
        "\n",
        "**Note: You can import all the libraries that you think will be required or can import it as you go along**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbvx0jKlmK75"
      },
      "source": [
        "import pandas as pd                                     # Data analysis and manipultion tool\n",
        "import numpy as np                                      # Fundamental package for linear algebra and multidimensional arrays\n",
        "import tensorflow as tf                                 # Deep Learning Tool\n",
        "import os                                               # OS module in Python provides a way of using operating system dependent functionality\n",
        "import cv2                                              # Library for image processing\n",
        "from sklearn.model_selection import train_test_split    # For splitting the data into train and validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJhV93bLAEX9"
      },
      "source": [
        "#Loading and preparing training data & Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9omJQVAmMOR"
      },
      "source": [
        "#Getting the labels of the images\n",
        "labels = pd.read_csv(\"/content/content/fruits_data/Training_set.csv\")   # loading the labels\n",
        "\n",
        "\n",
        "#Getting images file path\n",
        "file_paths = [[fname, '/content/content/fruits_data/train/' + fname] for fname in labels['filename']]\n",
        "\n",
        "\n",
        "#Converting the file_paths to dataframe\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "\n",
        "#Combining the labels with the images\n",
        "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train_data['label'] = le.fit_transform(train_data['label'])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "It is necessary to bring all the images in the same shape and size, also convert them to their pixel values because all machine learning \n",
        "or deep learning models accepts only the numerical data. Also we need to convert all the labels from categorical to numerical values.\n",
        "\"\"\"\n",
        "data = []     # initialize an empty numpy array\n",
        "image_size = 100      # image size taken is 100 here. one can take other size too\n",
        "for i in range(len(train_data)):\n",
        "  \n",
        "  img_array = cv2.imread(train_data['filepaths'][i])   # converting the image to gray scale\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))      # resizing the image array\n",
        "  data.append([new_img_array, train_data['label'][i]])\n",
        "\n",
        "#Shuffle the data\n",
        "np.random.shuffle(data)\n",
        "\n",
        "#Separating the images and labels\n",
        "x = []\n",
        "y = []\n",
        "for image in data:\n",
        "  x.append(image[0])\n",
        "  y.append(image[1])\n",
        "\n",
        "# converting x & y to numpy array as they are list\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "x =  x.reshape(-1, 100, 100, 3)\n",
        "\n",
        "#Splitting the data into Train and Validation Set\n",
        "# split the data\n",
        "\"\"\"\n",
        "We want to check the performance of the model that we built. For this purpose, we always split (both independent and dependent data) the given data into \n",
        "training set which will be used to train the model,  and test set which will be used to check how accurately the model is predicting outcomes.\n",
        "\"\"\"\n",
        "X_train, X_val, y_train, y_val = train_test_split(x,y,test_size=0.4, random_state = 42)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_val = X_val.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igvi42-iA8y-"
      },
      "source": [
        "#Building Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd7CPfzzmNj1",
        "outputId": "7ae721dc-9b91-4505-ef96-9a9ebd6b24bb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, losses, Model\n",
        "\n",
        "\n",
        "base_model = tf.keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = False, input_shape = (100,100,3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "x= layers.Flatten()(base_model.output)\n",
        "x= layers.Dense(150, activation='relu')(x)\n",
        "x= layers.Dropout(0.3)(x)\n",
        "predictions = layers.Dense(131, activation = 'softmax')(x)\n",
        "head_model = Model(inputs = base_model.input, outputs = predictions)\n",
        "head_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               691350    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 131)               19781     \n",
            "=================================================================\n",
            "Total params: 15,425,819\n",
            "Trainable params: 711,131\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWDmUtLHmR8S",
        "outputId": "52fd7fea-6b5d-499c-993f-bd7ae83c9b69"
      },
      "source": [
        "head_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "head_model.fit(X_train, y_train, batch_size=128, epochs=15, validation_data=(X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 1.9353 - accuracy: 0.5735 - val_loss: 0.3555 - val_accuracy: 0.9620\n",
            "Epoch 2/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.4037 - accuracy: 0.9083 - val_loss: 0.1148 - val_accuracy: 0.9886\n",
            "Epoch 3/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.1913 - accuracy: 0.9592 - val_loss: 0.0443 - val_accuracy: 0.9965\n",
            "Epoch 4/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.1120 - accuracy: 0.9783 - val_loss: 0.0250 - val_accuracy: 0.9986\n",
            "Epoch 5/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.0780 - accuracy: 0.9853 - val_loss: 0.0161 - val_accuracy: 0.9991\n",
            "Epoch 6/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.0558 - accuracy: 0.9902 - val_loss: 0.0105 - val_accuracy: 0.9995\n",
            "Epoch 7/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.0452 - accuracy: 0.9922 - val_loss: 0.0076 - val_accuracy: 0.9997\n",
            "Epoch 8/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.0342 - accuracy: 0.9943 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 9/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.0294 - accuracy: 0.9947 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.0245 - accuracy: 0.9960 - val_loss: 0.0033 - val_accuracy: 0.9998\n",
            "Epoch 11/15\n",
            "223/223 [==============================] - 248s 1s/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 0.0023 - val_accuracy: 0.9999\n",
            "Epoch 12/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 14/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "223/223 [==============================] - 249s 1s/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.0013 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0dbc60710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9LE-IWLmWhR",
        "outputId": "e5a6e03d-7a99-43e9-f677-6d23538478b4"
      },
      "source": [
        "#Validate the model\n",
        "head_model.evaluate(X_val,y_val)\n",
        "\n",
        "#head_model.save('Fruits_360.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "593/593 [==============================] - 110s 185ms/step - loss: 0.0013 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0013216972583904862, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76DN56VCBJr7"
      },
      "source": [
        "#Predict The Output For Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJiQVUQwmZOj"
      },
      "source": [
        "#Load Test Set\n",
        "test_image_order = pd.read_csv(\"/content/content/fruits_data/Testing_set.csv\")\n",
        "\n",
        "#Getting images file path\n",
        "file_paths = [[fname, '/content/content/fruits_data/test/' + fname] for fname in test_image_order['filename']]\n",
        "\n",
        "#Converting the file_paths to dataframe\n",
        "test_images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "\n",
        "#Data Pre-processing on test_data\n",
        "test_pixel_data = []     # initialize an empty numpy array\n",
        "image_size = 100      # image size taken is 100 here. one can take other size too\n",
        "for i in range(len(test_images)):\n",
        "  \n",
        "  img_array = cv2.imread(test_images['filepaths'][i])   # converting the image to gray scale\n",
        "\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))      # resizing the image array\n",
        "\n",
        "  test_pixel_data.append(new_img_array)\n",
        "\n",
        "\n",
        "test_pixel_data = np.array(test_pixel_data)\n",
        "\n",
        "test_pixel_data =  test_pixel_data.reshape(-1, 100, 100, 3)\n",
        "\n",
        "\n",
        "test_pixel_data = test_pixel_data.astype('float32')/255\n",
        "\n",
        "#Make Prediction on Test Dataset\n",
        "pred = head_model.predict(test_pixel_data)\n",
        "\n",
        "prediction = []\n",
        "for value in pred:\n",
        "  prediction.append(np.argmax(value))\n",
        "\n",
        "predictions = le.inverse_transform(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To35WF4NBav0"
      },
      "source": [
        "#Save prediction results locally via colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zlk0CH0rmaaC",
        "outputId": "c3b6ea7f-d85e-4d31-f03f-7d92cca5e630"
      },
      "source": [
        "res = pd.DataFrame({'filename': test_images['filename'], 'label': predictions})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
        "res.to_csv(\"submission.csv\", index = False) \n",
        "\n",
        "# To download the csv file locally\n",
        "from google.colab import files        \n",
        "files.download('submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c6d848f2-464d-4bc5-acb0-dbfe357badbf\", \"submission.csv\", 545203)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtQaqr2XBdok"
      },
      "source": [
        "#For people who work locally : Save prediciton results locally via jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGElvAkY1YRH"
      },
      "source": [
        "res = pd.DataFrame({'filename': test_images['filename'], 'label': predictions}) # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
        "res.to_csv(\"submission.csv\", index = False) # the csv file will be saved locally on the same location where this notebook is located."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}